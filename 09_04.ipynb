{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c861e298",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain\n",
      "  Downloading langchain-0.2.7-py3-none-any.whl (983 kB)\n",
      "     -------------------------------------- 983.6/983.6 kB 2.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in c:\\users\\inpt\\anaconda3\\lib\\site-packages (from langchain) (0.1.85)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in c:\\users\\inpt\\anaconda3\\lib\\site-packages (from langchain) (8.5.0)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in c:\\users\\inpt\\anaconda3\\lib\\site-packages (from langchain) (4.0.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\inpt\\anaconda3\\lib\\site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\inpt\\anaconda3\\lib\\site-packages (from langchain) (2.5.3)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\inpt\\anaconda3\\lib\\site-packages (from langchain) (2.0.31)\n",
      "Collecting langchain-text-splitters<0.3.0,>=0.2.0\n",
      "  Downloading langchain_text_splitters-0.2.2-py3-none-any.whl (25 kB)\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.12 in c:\\users\\inpt\\anaconda3\\lib\\site-packages (from langchain) (0.2.17)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\inpt\\anaconda3\\lib\\site-packages (from langchain) (3.8.4)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\inpt\\anaconda3\\lib\\site-packages (from langchain) (1.26.4)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\inpt\\anaconda3\\lib\\site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in c:\\users\\inpt\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (3.3.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\inpt\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\inpt\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\inpt\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\inpt\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\inpt\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\inpt\\anaconda3\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.12->langchain) (23.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\inpt\\anaconda3\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.12->langchain) (1.33)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\inpt\\anaconda3\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.6)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\inpt\\anaconda3\\lib\\site-packages (from pydantic<3,>=1->langchain) (4.12.2)\n",
      "Requirement already satisfied: pydantic-core==2.14.6 in c:\\users\\inpt\\anaconda3\\lib\\site-packages (from pydantic<3,>=1->langchain) (2.14.6)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\inpt\\anaconda3\\lib\\site-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\inpt\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (2024.7.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\inpt\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\inpt\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (2.2.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\inpt\\anaconda3\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\inpt\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.12->langchain) (3.0.0)\n",
      "Installing collected packages: langchain-text-splitters, langchain\n",
      "Successfully installed langchain-0.2.7 langchain-text-splitters-0.2.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8392a642",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "········\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "os.environ[\"MISTRAL_API_KEY\"] = getpass.getpass()\n",
    "\n",
    "from langchain_mistralai import ChatMistralAI\n",
    "\n",
    "model = ChatMistralAI(model=\"mistral-large-latest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "200dcf37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importer les modules nécessaires\n",
    "from langchain.prompts import PromptTemplate\n",
    "#from langchain.llms import Mistral\n",
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "344e1088",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer un modèle de prompt\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"input_text\"],\n",
    "    template=\"Voici un texte : {input_text}\\n\\nPeux-tu me donner un résumé de 3 lignes de ce texte ?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e3db993d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer une chaîne avec LangChain\n",
    "chain = LLMChain(\n",
    "    llm=model,\n",
    "    prompt=prompt_template\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "01170d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utiliser la chaîne pour résumer un texte\n",
    "input_text = \"Les modèles de langage de grande taille (LLMs) représentent une avancée majeure dans le domaine de l'intelligence artificielle. Conçus pour comprendre et générer du texte de manière cohérente, ils sont basés sur des architectures telles que les transformateurs, qui permettent de traiter efficacement de grandes quantités de données. Ces modèles sont formés sur des corpus vastes et diversifiés, leur permettant de saisir les nuances du langage humain. Les LLMs fonctionnent en prédisant la probabilité des mots ou phrases suivantes dans un texte, en se basant sur le contexte fourni. Ils peuvent être utilisés pour une variété d'applications, allant de la génération de texte à la traduction automatique, en passant par la réponse à des questions complexes et la création de contenu. Cependant, leur utilisation soulève des questions éthiques et pratiques. Les biais présents dans les données d'entraînement peuvent être reproduits dans les réponses générées, et la gestion des informations sensibles est cruciale. De plus, l'énorme puissance de calcul requise pour former ces modèles soulève des préoccupations environnementales. En dépit de ces défis, les LLMs continuent d'évoluer, offrant des opportunités prometteuses pour améliorer la communication et l'analyse de données dans de nombreux domaines. Ils représentent une frontière avancée de la recherche en IA, avec des applications potentielles qui ne cessent de se développer.\"\n",
    "result = chain.run(input_text=input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6a53cc86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Résumé : Les modèles de langage de grande taille (LLMs) sont une percée importante dans le domaine de l'IA, capables de comprendre et de générer du texte de manière cohérente grâce à des architectures comme les transformateurs. Ils sont formés sur de vastes corpus et peuvent être utilisés dans diverses applications, de la génération de texte à la traduction automatique. Cependant, leur utilisation pose des défis éthiques et pratiques, tels que la reproduction de biais et la gestion de l'impact environnemental de leur puissance de calcul élevée. Malgré ces défis, les LLMs continuent d'évoluer, offrant des opportunités prometteuses dans de nombreux domaines.\n"
     ]
    }
   ],
   "source": [
    "print(\"Résumé :\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3808085d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
